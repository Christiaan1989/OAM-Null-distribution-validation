#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Fri Jun  1 14:50:14 2018

@author: christiaanbecker
"""

#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Mon Apr 16 18:09:19 2018

@author: christiaanbecker
"""
import nipype.interfaces.spm as spm
import nipype.interfaces.fsl as fsl
import nilearn.image as image
from nilearn.input_data import NiftiMasker
from nilearn.image import new_img_like
from nilearn.plotting import plot_stat_map
from nilearn.plotting import plot_roi
from nilearn import plotting
from nilearn.masking import compute_epi_mask
from nilearn.masking import compute_background_mask
from scipy import stats
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import nibabel as nib
import matplotlib.mlab as mlab
from scipy.stats import ks_2samp
from nilearn.plotting import plot_epi, show
import seaborn as sns
from nilearn.masking import apply_mask
import statsmodels.api as sm
from scipy.stats import norm
from numpy import linspace
from nilearn.masking import apply_mask
from nilearn import masking
from nilearn import datasets
from nilearn.input_data import NiftiLabelsMasker
from os.path import join as opj
from nipype.interfaces.io import SelectFiles, DataSink
from nipype.interfaces.spm import (OneSampleTTestDesign, EstimateModel,
                                   EstimateContrast, Threshold)
from nipype.interfaces.utility import IdentityInterface
from nipype.pipeline.engine import Workflow, Node
from nipype.interfaces.fsl import Info
from nipype.algorithms.misc import Gunzip
import nipype.interfaces.io as nio
import traits 
from random import shuffle
import random
import nibabel as nb
import numpy as np
import sys
import os
import argparse
import glob
import xlsxwriter
import shutil

#Fn = 53

# global variables / flags

# for debugging / information
debug = True
verbose = True

# for saving intermediate data
savezscores = True
saveavgfmri = True

# convenience labels
X=0
Y=1
Z=2
T=3





##############################################################AOM ISC _analysis#################################################################################################################


for q in range(56,58):

    Dictionary = {u'NYU_0051090_func_preproc.nii.gz': u'NYU_0051090_mask_files.nii.gz', u'NYU_0051122_func_preproc.nii.gz': u'NYU_0051122_mask_files.nii.gz', u'NYU_0051062_func_preproc.nii.gz': u'NYU_0051062_mask_files.nii.gz', u'NYU_0051086_func_preproc.nii.gz': u'NYU_0051086_mask_files.nii.gz', u'NYU_0051047_func_preproc.nii.gz': u'NYU_0051047_mask_files.nii.gz', u'NYU_0051093_func_preproc.nii.gz': u'NYU_0051093_mask_files.nii.gz', u'NYU_0051101_func_preproc.nii.gz': u'NYU_0051101_mask_files.nii.gz', u'NYU_0051079_func_preproc.nii.gz': u'NYU_0051079_mask_files.nii.gz', u'NYU_0051053_func_preproc.nii.gz': u'NYU_0051053_mask_files.nii.gz', u'NYU_0051118_func_preproc.nii.gz': u'NYU_0051118_mask_files.nii.gz', u'NYU_0051074_func_preproc.nii.gz': u'NYU_0051074_mask_files.nii.gz', u'NYU_0051147_func_preproc.nii.gz': u'NYU_0051147_mask_files.nii.gz', u'NYU_0051065_func_preproc.nii.gz': u'NYU_0051065_mask_files.nii.gz', u'NYU_0051099_func_preproc.nii.gz': u'NYU_0051099_mask_files.nii.gz', u'NYU_0051080_func_preproc.nii.gz': u'NYU_0051080_mask_files.nii.gz', u'NYU_0051060_func_preproc.nii.gz': u'NYU_0051060_mask_files.nii.gz', u'NYU_0051088_func_preproc.nii.gz': u'NYU_0051088_mask_files.nii.gz', u'NYU_0051097_func_preproc.nii.gz': u'NYU_0051097_mask_files.nii.gz', u'NYU_0051149_func_preproc.nii.gz': u'NYU_0051149_mask_files.nii.gz', u'NYU_0051045_func_preproc.nii.gz': u'NYU_0051045_mask_files.nii.gz', u'NYU_0051123_func_preproc.nii.gz': u'NYU_0051123_mask_files.nii.gz', u'NYU_0051067_func_preproc.nii.gz': u'NYU_0051067_mask_files.nii.gz', u'NYU_0051104_func_preproc.nii.gz': u'NYU_0051104_mask_files.nii.gz', u'NYU_0051150_func_preproc.nii.gz': u'NYU_0051150_mask_files.nii.gz', u'NYU_0051151_func_preproc.nii.gz': u'NYU_0051151_mask_files.nii.gz', u'NYU_0051050_func_preproc.nii.gz': u'NYU_0051050_mask_files.nii.gz', u'NYU_0051128_func_preproc.nii.gz': u'NYU_0051128_mask_files.nii.gz', u'NYU_0051038_func_preproc.nii.gz': u'NYU_0051038_mask_files.nii.gz', u'NYU_0051084_func_preproc.nii.gz': u'NYU_0051084_mask_files.nii.gz', u'NYU_0051089_func_preproc.nii.gz': u'NYU_0051089_mask_files.nii.gz', u'NYU_0051121_func_preproc.nii.gz': u'NYU_0051121_mask_files.nii.gz', u'NYU_0051044_func_preproc.nii.gz': u'NYU_0051044_mask_files.nii.gz', u'NYU_0051091_func_preproc.nii.gz': u'NYU_0051091_mask_files.nii.gz', u'NYU_0051098_func_preproc.nii.gz': u'NYU_0051098_mask_files.nii.gz', u'NYU_0051075_func_preproc.nii.gz': u'NYU_0051075_mask_files.nii.gz', u'NYU_0051096_func_preproc.nii.gz': u'NYU_0051096_mask_files.nii.gz', u'NYU_0051103_func_preproc.nii.gz': u'NYU_0051103_mask_files.nii.gz', u'NYU_0051153_func_preproc.nii.gz': u'NYU_0051153_mask_files.nii.gz', u'NYU_0051087_func_preproc.nii.gz': u'NYU_0051087_mask_files.nii.gz', u'NYU_0051156_func_preproc.nii.gz': u'NYU_0051156_mask_files.nii.gz', u'NYU_0051117_func_preproc.nii.gz': u'NYU_0051117_mask_files.nii.gz', u'NYU_0051039_func_preproc.nii.gz': u'NYU_0051039_mask_files.nii.gz', u'NYU_0051095_func_preproc.nii.gz': u'NYU_0051095_mask_files.nii.gz', u'NYU_0051054_func_preproc.nii.gz': u'NYU_0051054_mask_files.nii.gz', u'NYU_0051063_func_preproc.nii.gz': u'NYU_0051063_mask_files.nii.gz', u'NYU_0051036_func_preproc.nii.gz': u'NYU_0051036_mask_files.nii.gz', u'NYU_0051082_func_preproc.nii.gz': u'NYU_0051082_mask_files.nii.gz', u'NYU_0051111_func_preproc.nii.gz': u'NYU_0051111_mask_files.nii.gz', u'NYU_0051064_func_preproc.nii.gz': u'NYU_0051064_mask_files.nii.gz', u'NYU_0051105_func_preproc.nii.gz': u'NYU_0051105_mask_files.nii.gz', u'NYU_0051078_func_preproc.nii.gz': u'NYU_0051078_mask_files.nii.gz', u'NYU_0051068_func_preproc.nii.gz': u'NYU_0051068_mask_files.nii.gz', u'NYU_0051055_func_preproc.nii.gz': u'NYU_0051055_mask_files.nii.gz', u'NYU_0051116_func_preproc.nii.gz': u'NYU_0051116_mask_files.nii.gz', u'NYU_0051041_func_preproc.nii.gz': u'NYU_0051041_mask_files.nii.gz', u'NYU_0051129_func_preproc.nii.gz': u'NYU_0051129_mask_files.nii.gz', u'NYU_0051076_func_preproc.nii.gz': u'NYU_0051076_mask_files.nii.gz', u'NYU_0051124_func_preproc.nii.gz': u'NYU_0051124_mask_files.nii.gz', u'NYU_0051113_func_preproc.nii.gz': u'NYU_0051113_mask_files.nii.gz', u'NYU_0051107_func_preproc.nii.gz': u'NYU_0051107_mask_files.nii.gz', u'NYU_0051146_func_preproc.nii.gz': u'NYU_0051146_mask_files.nii.gz', u'NYU_0051056_func_preproc.nii.gz': u'NYU_0051056_mask_files.nii.gz', u'NYU_0051114_func_preproc.nii.gz': u'NYU_0051114_mask_files.nii.gz', u'NYU_0051154_func_preproc.nii.gz': u'NYU_0051154_mask_files.nii.gz', u'NYU_0051046_func_preproc.nii.gz': u'NYU_0051046_mask_files.nii.gz', u'NYU_0051083_func_preproc.nii.gz': u'NYU_0051083_mask_files.nii.gz', u'NYU_0051131_func_preproc.nii.gz': u'NYU_0051131_mask_files.nii.gz', u'NYU_0051112_func_preproc.nii.gz': u'NYU_0051112_mask_files.nii.gz', u'NYU_0051049_func_preproc.nii.gz': u'NYU_0051049_mask_files.nii.gz', u'NYU_0051106_func_preproc.nii.gz': u'NYU_0051106_mask_files.nii.gz', u'NYU_0051072_func_preproc.nii.gz': u'NYU_0051072_mask_files.nii.gz', u'NYU_0051058_func_preproc.nii.gz': u'NYU_0051058_mask_files.nii.gz', u'NYU_0051148_func_preproc.nii.gz': u'NYU_0051148_mask_files.nii.gz', u'NYU_0051051_func_preproc.nii.gz': u'NYU_0051051_mask_files.nii.gz', u'NYU_0051057_func_preproc.nii.gz': u'NYU_0051057_mask_files.nii.gz', u'NYU_0051126_func_preproc.nii.gz': u'NYU_0051126_mask_files.nii.gz', u'NYU_0051109_func_preproc.nii.gz': u'NYU_0051109_mask_files.nii.gz', u'NYU_0051040_func_preproc.nii.gz': u'NYU_0051040_mask_files.nii.gz', u'NYU_0051152_func_preproc.nii.gz': u'NYU_0051152_mask_files.nii.gz', u'NYU_0051073_func_preproc.nii.gz': u'NYU_0051073_mask_files.nii.gz', u'NYU_0051048_func_preproc.nii.gz': u'NYU_0051048_mask_files.nii.gz', u'NYU_0051094_func_preproc.nii.gz': u'NYU_0051094_mask_files.nii.gz', u'NYU_0051159_func_preproc.nii.gz': u'NYU_0051159_mask_files.nii.gz', u'NYU_0051102_func_preproc.nii.gz': u'NYU_0051102_mask_files.nii.gz', u'NYU_0051081_func_preproc.nii.gz': u'NYU_0051081_mask_files.nii.gz', u'NYU_0051110_func_preproc.nii.gz': u'NYU_0051110_mask_files.nii.gz', u'NYU_0051069_func_preproc.nii.gz': u'NYU_0051069_mask_files.nii.gz', u'NYU_0051042_func_preproc.nii.gz': u'NYU_0051042_mask_files.nii.gz', u'NYU_0051127_func_preproc.nii.gz': u'NYU_0051127_mask_files.nii.gz', u'NYU_0051061_func_preproc.nii.gz': u'NYU_0051061_mask_files.nii.gz', u'NYU_0051070_func_preproc.nii.gz': u'NYU_0051070_mask_files.nii.gz', u'NYU_0051130_func_preproc.nii.gz': u'NYU_0051130_mask_files.nii.gz', u'NYU_0051066_func_preproc.nii.gz': u'NYU_0051066_mask_files.nii.gz', u'NYU_0051052_func_preproc.nii.gz': u'NYU_0051052_mask_files.nii.gz', u'NYU_0051059_func_preproc.nii.gz': u'NYU_0051059_mask_files.nii.gz', u'NYU_0051155_func_preproc.nii.gz': u'NYU_0051155_mask_files.nii.gz', u'NYU_0051077_func_preproc.nii.gz': u'NYU_0051077_mask_files.nii.gz', u'NYU_0051071_func_preproc.nii.gz': u'NYU_0051071_mask_files.nii.gz', u'NYU_0051100_func_preproc.nii.gz': u'NYU_0051100_mask_files.nii.gz', u'NYU_0051085_func_preproc.nii.gz': u'NYU_0051085_mask_files.nii.gz'}

    fFiles = [u'NYU_0051036_func_preproc.nii.gz', u'NYU_0051038_func_preproc.nii.gz', u'NYU_0051039_func_preproc.nii.gz', u'NYU_0051040_func_preproc.nii.gz', u'NYU_0051041_func_preproc.nii.gz', u'NYU_0051042_func_preproc.nii.gz', u'NYU_0051044_func_preproc.nii.gz', u'NYU_0051045_func_preproc.nii.gz', u'NYU_0051046_func_preproc.nii.gz', u'NYU_0051047_func_preproc.nii.gz', u'NYU_0051048_func_preproc.nii.gz', u'NYU_0051050_func_preproc.nii.gz', u'NYU_0051051_func_preproc.nii.gz', u'NYU_0051052_func_preproc.nii.gz', u'NYU_0051053_func_preproc.nii.gz', u'NYU_0051054_func_preproc.nii.gz', u'NYU_0051055_func_preproc.nii.gz', u'NYU_0051056_func_preproc.nii.gz', u'NYU_0051057_func_preproc.nii.gz', u'NYU_0051058_func_preproc.nii.gz', u'NYU_0051059_func_preproc.nii.gz', u'NYU_0051060_func_preproc.nii.gz', u'NYU_0051061_func_preproc.nii.gz', u'NYU_0051062_func_preproc.nii.gz', u'NYU_0051063_func_preproc.nii.gz', u'NYU_0051064_func_preproc.nii.gz', u'NYU_0051065_func_preproc.nii.gz', u'NYU_0051066_func_preproc.nii.gz', u'NYU_0051067_func_preproc.nii.gz', u'NYU_0051068_func_preproc.nii.gz', u'NYU_0051069_func_preproc.nii.gz', u'NYU_0051071_func_preproc.nii.gz', u'NYU_0051072_func_preproc.nii.gz', u'NYU_0051073_func_preproc.nii.gz', u'NYU_0051074_func_preproc.nii.gz', u'NYU_0051076_func_preproc.nii.gz', u'NYU_0051077_func_preproc.nii.gz', u'NYU_0051078_func_preproc.nii.gz', u'NYU_0051079_func_preproc.nii.gz', u'NYU_0051080_func_preproc.nii.gz', u'NYU_0051081_func_preproc.nii.gz', u'NYU_0051082_func_preproc.nii.gz', u'NYU_0051083_func_preproc.nii.gz', u'NYU_0051084_func_preproc.nii.gz', u'NYU_0051085_func_preproc.nii.gz', u'NYU_0051086_func_preproc.nii.gz', u'NYU_0051087_func_preproc.nii.gz', u'NYU_0051088_func_preproc.nii.gz', u'NYU_0051089_func_preproc.nii.gz', u'NYU_0051090_func_preproc.nii.gz', u'NYU_0051091_func_preproc.nii.gz', u'NYU_0051093_func_preproc.nii.gz', u'NYU_0051094_func_preproc.nii.gz', u'NYU_0051095_func_preproc.nii.gz', u'NYU_0051096_func_preproc.nii.gz', u'NYU_0051097_func_preproc.nii.gz', u'NYU_0051098_func_preproc.nii.gz', u'NYU_0051099_func_preproc.nii.gz', u'NYU_0051100_func_preproc.nii.gz', u'NYU_0051101_func_preproc.nii.gz', u'NYU_0051102_func_preproc.nii.gz', u'NYU_0051103_func_preproc.nii.gz', u'NYU_0051104_func_preproc.nii.gz', u'NYU_0051105_func_preproc.nii.gz', u'NYU_0051106_func_preproc.nii.gz', u'NYU_0051107_func_preproc.nii.gz', u'NYU_0051109_func_preproc.nii.gz', u'NYU_0051110_func_preproc.nii.gz', u'NYU_0051111_func_preproc.nii.gz', u'NYU_0051112_func_preproc.nii.gz', u'NYU_0051113_func_preproc.nii.gz', u'NYU_0051114_func_preproc.nii.gz', u'NYU_0051116_func_preproc.nii.gz', u'NYU_0051117_func_preproc.nii.gz', u'NYU_0051118_func_preproc.nii.gz', u'NYU_0051121_func_preproc.nii.gz', u'NYU_0051122_func_preproc.nii.gz', u'NYU_0051123_func_preproc.nii.gz', u'NYU_0051124_func_preproc.nii.gz', u'NYU_0051126_func_preproc.nii.gz', u'NYU_0051127_func_preproc.nii.gz', u'NYU_0051128_func_preproc.nii.gz', u'NYU_0051129_func_preproc.nii.gz', u'NYU_0051130_func_preproc.nii.gz', u'NYU_0051131_func_preproc.nii.gz', u'NYU_0051146_func_preproc.nii.gz', u'NYU_0051147_func_preproc.nii.gz', u'NYU_0051148_func_preproc.nii.gz', u'NYU_0051149_func_preproc.nii.gz', u'NYU_0051150_func_preproc.nii.gz', u'NYU_0051151_func_preproc.nii.gz', u'NYU_0051152_func_preproc.nii.gz', u'NYU_0051153_func_preproc.nii.gz', u'NYU_0051154_func_preproc.nii.gz', u'NYU_0051155_func_preproc.nii.gz', u'NYU_0051156_func_preproc.nii.gz', u'NYU_0051159_func_preproc.nii.gz']

    transform_files = ['NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz','NYU_0051041_mask_files_mapping.nii.gz']

    
    random.shuffle(fFiles)


    fmri_files = fFiles[:19]

    mask_files = [Dictionary[fFiles[0]], Dictionary[fFiles[1]],Dictionary[fFiles[2]],Dictionary[fFiles[3]],Dictionary[fFiles[4]],Dictionary[fFiles[5]],Dictionary[fFiles[6]],Dictionary[fFiles[7]],Dictionary[fFiles[8]],Dictionary[fFiles[9]],Dictionary[fFiles[10]],Dictionary[fFiles[11]],Dictionary[fFiles[12]],Dictionary[fFiles[13]],Dictionary[fFiles[14]],Dictionary[fFiles[15]],Dictionary[fFiles[16]],Dictionary[fFiles[17]],Dictionary[fFiles[18]]]

    
    nruns = 1
    nsubjects = int(len(fmri_files)/nruns)
    
    
    workbook = xlsxwriter.Workbook('/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/Files_used _in _Analysis.xlsx'.format(q))
    worksheet = workbook.add_worksheet()
    
    worksheet.write('A1', 'Files')
    
    
    
    row = 1
    col = 0
    
    
    
    for Files in (fmri_files):
        worksheet.write(row, col, Files)
        row += 1
    
    
    workbook.close()
    
    
    
    outdir = '/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/'.format(q)
    print("input/output directory: "+outdir)





    def inter_subject_correlation(fmri_files, mask_files, transform_files, outdir, nsubjects, subjects=None,
                                    nruns=1, runs=None, skip_first=3, skip_last=0, meancutoff=0.0001, groupcutoff=0.5) :
    
        # 0. setup global variables and such
        basename = os.path.basename(fmri_files[0])
        basename = basename.split(".")
    
        # if subjects,runs not set build from numbers
        if (subjects==None) :         
            subjects = []
            for sub in range(nsubjects):
                for run in range(nruns):
                     subjects.append(int(sub)+1)
    
        if (runs==None) :         
            runs = []
            for sub in range(nsubjects):
                for run in range(nruns):
                    runs.append(int(run)+1)
    
        print('ISC: '+str(nsubjects)+" subjects x "+str(nruns)+" runs, (mc,gc,sf,sl): ",meancutoff,groupcutoff,skip_first,skip_last)
    
        # 1. build a global average of all subjects (removing voxels with low intensity, missing values, and z-scoring the rest)
        (avgfmri, avgcount, avgmask, p0, pM, runtimes) = build_average(fmri_files, mask_files, transform_files, outdir,
                                                                        nsubjects, subjects, nruns, runs,
                                                                        skip_first, skip_last, meancutoff, groupcutoff)
        
        # 2. for each subject, remove data from the average and compute the correlation
        correlation = compute_subject_correlations(fmri_files, mask_files, transform_files, outdir,
                                                   nsubjects, subjects, nruns, runs, 
                                                   skip_first, skip_last, meancutoff,
                                                   avgfmri, avgcount, avgmask, p0, pM, runtimes)
        
        # export results (resampled to avg space)
        transform = nb.load(transform_files[0])
        nx = transform.header.get_data_shape()[X]
        ny = transform.header.get_data_shape()[Y]
        nz = transform.header.get_data_shape()[Z]
        resampled = np.zeros((nx,ny,nz,nsubjects))
        for x in range(p0[X],pM[X]):
            for y in range(p0[Y],pM[Y]):
                for z in range(p0[Z],pM[Z]):
                    if (avgmask[x,y,z]>0) :
                        for s in range(nsubjects):
                            resampled[x,y,z,s] = correlation[x-p0[X],y-p0[Y],z-p0[Z],s]
                            
        outname = outdir+basename[0]+"_isc"+str(nsubjects)+"x"+str(nruns)+"_corr."+".".join(basename[1:])
        print("saving to: "+outname)
        outimg = nb.Nifti1Image(resampled, transform.affine, transform.header)
        outimg.header['cal_min'] = np.min(resampled)
        outimg.header['cal_max'] = np.max(resampled)
        outimg.to_filename(outname)
        
        # 3. additional statistics?
    
        # outputs the filename rather than the entire file itself for easier handling
        return outname
    
    
    def compute_subject_correlations(fmri_files, mask_files, transform_files, outdir,
                                    nsubjects, subjects, nruns, runs,
                                    skip_first, skip_last, meancutoff,
                                    avgfmri, avgcount, avgmask, p0, pM, runtimes) :
    
        # test for consistency
        # here we assume the same numbers of subjects x runs for all data
        # (different versions could be made for simpler cases)
        if not ( len(fmri_files) == len(mask_files) and len(fmri_files) == len(transform_files) and len(fmri_files) == nsubjects*nruns):
            print("!different number of masks, transform and fmri data than specified subjects and runs!")
            return
    
        # for each subject, remove from average and correlate
        if debug : print("inter-subject correlations")    
        correlation = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z],nsubjects))
        for s in range(nsubjects) :
            if debug : print("subject: "+str(s+1))    
    
            # keep sums in case of multiple runs per subject
            
            covar = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z]))
            var_sub = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z]))
            var_avg = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z]))
            samples = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z]))
    
            for r in range(nruns) :
                if debug : print("run: "+str(r+1))    
    
                # search for (subject,run) combination
                idx = -1
                for n in range(len(fmri_files)) :
                    if (subjects[n]==s+1 and runs[n]==r+1) : 
                        idx = n
                        break
                if (idx>-1) :
                    if debug : print("data set: "+str(idx+1))    
                    
                    subjectrun = nb.load(fmri_files[idx])
                    fmri = subjectrun.get_data()
                    transform = nb.load(transform_files[idx]).get_data()
                    mask = nb.load(mask_files[idx]).get_data()
                
                    fmri = build_zscore(fmri, mask, transform, skip_first, skip_last, meancutoff)
                    
                    # remove from global average
                    for x in range(p0[X],pM[X]):
                        for y in range(p0[Y],pM[Y]):
                            for z in range(p0[Z],pM[Z]):
                                if (avgmask[x,y,z]>0) :
                                    xp = int(np.rint(transform[x,y,z,X]))
                                    yp = int(np.rint(transform[x,y,z,Y]))
                                    zp = int(np.rint(transform[x,y,z,Z]))
                                
                                    if (mask[xp,yp,zp]>0) : # only where you have valid data
                                        for t in range(skip_first, fmri.shape[T]-skip_last) :
                                            # remove normalization
                                            avgdata = avgfmri[x-p0[X],y-p0[Y],z-p0[Z],runtimes[r]+t-skip_first] \
                                                     *avgcount[x-p0[X],y-p0[Y],z-p0[Z],r]
                                            # remove data value
                                            avgdata -= fmri[xp,yp,zp,t]
                                            # re-normalize
                                            avgdata /= (avgcount[x-p0[X],y-p0[Y],z-p0[Z],r]-1)
                                            # update variances and covariance
                                            covar[x-p0[X],y-p0[Y],z-p0[Z]] += fmri[xp,yp,zp,t]*avgdata
                                            var_sub[x-p0[X],y-p0[Y],z-p0[Z]] += fmri[xp,yp,zp,t]*fmri[xp,yp,zp,t]
                                            var_avg[x-p0[X],y-p0[Y],z-p0[Z]] += avgdata*avgdata
                                            samples[x-p0[X],y-p0[Y],z-p0[Z]] += 1
    
            # compute the final correlations
            for x in range(p0[X],pM[X]):
                for y in range(p0[Y],pM[Y]):
                    for z in range(p0[Z],pM[Z]):
                        if (avgmask[x,y,z]>0) :
                            correlation[x-p0[X],y-p0[Y],z-p0[Z],s] = covar[x-p0[X],y-p0[Y],z-p0[Z]] \
                                                                    /np.sqrt(var_sub[x-p0[X],y-p0[Y],z-p0[Z]]) \
                                                                    /np.sqrt(var_avg[x-p0[X],y-p0[Y],z-p0[Z]])
                                                   
        return correlation                       
    
    
    def build_average( fmri_files, mask_files, transform_files, outdir,
                        nsubjects, subjects, nruns, runs, skip_first, skip_last, 
                        meancutoff, groupcutoff) :
        
        # test for consistency
        # here we assume the same numbers of subjects x runs for all data
        # (different versions could be made for simpler cases)
        if not ( len(fmri_files) == len(mask_files) and len(fmri_files) == len(transform_files) and len(fmri_files) == nsubjects*nruns):
            print("!different number of masks, transform and fmri data than specified subjects and runs!")
            return
            
        # init from first subject
        if debug : print("opening file: "+mask_files[0])
        mask = nb.load(mask_files[0]).get_data()
        
        if debug : print("opening file: "+transform_files[0])
        transform = nb.load(transform_files[0]).get_data()
        
        # define common space: every non-zero element of the mask is used
        nx = transform.shape[X]
        ny = transform.shape[Y]
        nz = transform.shape[Z]
        
        avgmask = np.zeros(transform.shape[X:T])
        for n in range(len(mask_files)) :
            if debug : print("subject: "+str(subjects[n])+", run:"+str(runs[n]))
            transform = nb.load(transform_files[n]).get_data()
            mask = nb.load(mask_files[n]).get_data()
    
            for x in range(nx):
                for y in range(ny):
                    for z in range(nz):
                        xp = int(np.rint(transform[x,y,z,X]))
                        yp = int(np.rint(transform[x,y,z,Y]))
                        zp = int(np.rint(transform[x,y,z,Z]))
                        avgmask[x,y,z] += mask[xp,yp,zp]
                 
        # find mask boundaries
        indices = np.nonzero(avgmask)
        p0 = (int(np.min(indices[X])),int(np.min(indices[Y])),int(np.min(indices[Z])))
        pM = (int(np.max(indices[X])+1),int(np.max(indices[Y])+1),int(np.max(indices[Z])+1))
        print("analysis bounding box (global space): "+str(p0)+", "+str(pM))
        
        # create average fmri only within the mask, concatenate the runs
        runtimes = list(range(nruns+1))
        # first run time is zero, simpler for later computations
        runtimes[0] = 0
        for n in range(nruns) :
            f = runs.index(n+1)
            fmri_time = nb.load(fmri_files[f]).header.get_data_shape()[T]
            runtimes[n+1] = int(runtimes[n] + fmri_time-skip_first-skip_last)
            
        if debug : print("runtimes: "+str(runtimes))    
                
        avgfmri = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z],runtimes[nruns]))
        # to count the number of subjects per run that contribute to each voxel
        avgcount = np.zeros((pM[X]-p0[X],pM[Y]-p0[Y],pM[Z]-p0[Z],nruns))
            
        # pull data from each time series
        # check for % missing data (below threshold) and mask out the bad ones
        # use the rest to build Z-scores
        # note: for simplicity, the number of missing data points is the maximum over runs per voxel
        if debug : print("global averaging")    
        for n in range(len(fmri_files)) :
            s = subjects[n]
            r = runs[n]
    
            if debug : print("subject: "+str(subjects[n])+", run: "+str(runs[n]))    
    
            subjectrun = nb.load(fmri_files[n])
            fmri = subjectrun.get_data()
            transform = nb.load(transform_files[n]).get_data()
            mask = nb.load(mask_files[n]).get_data()
        
            fmri = build_zscore(fmri, mask, transform, skip_first, skip_last, meancutoff)
            # option: save the masked, z-scored time series?
            if savezscores :
                imgname = os.path.basename(fmri_files[n])
                basename = imgname.split(".")
                outname = outdir+basename[0]+"_zscored."+'.'.join(basename[1:])
                print("saving to: "+outname)
                outimg = nb.Nifti1Image(fmri, subjectrun.affine, subjectrun.header)
                outimg.header['cal_min'] = np.min(fmri)
                outimg.header['cal_max'] = np.max(fmri)
                outimg.to_filename(outname)	
    
            # build the global average
            for x in range(p0[X],pM[X]):
                for y in range(p0[Y],pM[Y]):
                    for z in range(p0[Z],pM[Z]):
                        xp = int(np.rint(transform[x,y,z,X]))
                        yp = int(np.rint(transform[x,y,z,Y]))
                        zp = int(np.rint(transform[x,y,z,Z]))
                        
                        if (mask[xp,yp,zp]>0) :
                            for t in range(skip_first, fmri.shape[T]-skip_last) :
                                avgfmri[x-p0[X],y-p0[Y],z-p0[Z],runtimes[r-1]+t-skip_first] += fmri[xp,yp,zp,t]
                            avgcount[x-p0[X],y-p0[Y],z-p0[Z],r-1] += 1
    						
        # final step: average, discard data with unsufficient number of subjects
        for x in range(p0[X],pM[X]):
            for y in range(p0[Y],pM[Y]):
                for z in range(p0[Z],pM[Z]):
                    for r in range(nruns) :
                        if (avgcount[x-p0[X],y-p0[Y],z-p0[Z],r]<=groupcutoff*nsubjects) :
                            avgmask[x,y,z] = 0
                    
                    if (avgmask[x,y,z]>0) :
                        for r in range(nruns) :
                            for t in range(runtimes[r], runtimes[r+1]) :
                                avgfmri[x-p0[X],y-p0[Y],z-p0[Z],t] /= avgcount[x-p0[X],y-p0[Y],z-p0[Z],r]
        if saveavgfmri :
            imgname = os.path.basename(fmri_files[0])
            basename = imgname.split(".")
            outname = outdir+basename[0]+"_avgfmri."+'.'.join(basename[1:])
            print("saving to: "+outname)
            outimg = nb.Nifti1Image(avgfmri, affine=None)
            outimg.to_filename(outname)	
            
            outname = outdir+basename[0]+"_avgcount."+'.'.join(basename[1:])
            print("saving to: "+outname)
            outimg = nb.Nifti1Image(avgcount, affine=None)
            outimg.to_filename(outname)	
            
            outname = outdir+basename[0]+"_avgmask."+'.'.join(basename[1:])
            print("saving to: "+outname)
            outimg = nb.Nifti1Image(avgmask, affine=None)
            outimg.to_filename(outname)	
                
        return (avgfmri, avgcount, avgmask, p0, pM, runtimes)
    
    
    def build_zscore(fmri, mask, transform, skip_first, skip_last, meancutoff) :
        nix = fmri.shape[X]
        niy = fmri.shape[Y]
        niz = fmri.shape[Z]
        # find mean, stdev,max within mask
        for xi in range(nix):
            for yi in range(niy):
                for zi in range(niz):
                    fmean = 0
                    fmax = 0
                    fden = 0
                    if (mask[xi,yi,zi]>0) :
                        for ti in range(skip_first, fmri.shape[T]-skip_last) :
                            fmean += fmri[xi,yi,zi,ti]
                            if (fmri[xi,yi,zi,ti]>fmax) : fmax = fmri[xi,yi,zi,ti]
                            fden += 1
                    if (fden>0) : fmean /= fden
                    
                    # mask out data with low raw values
                    if (fmean<=meancutoff*fmax) : mask[xi,yi,zi] = 0
                    
                    fstd = 0
                    if (mask[xi,yi,zi]>0) :
                        for ti in range(skip_first, fmri.shape[T]-skip_last) :
                            fmri[xi,yi,zi,ti] -= fmean
                            fstd += fmri[xi,yi,zi,ti]*fmri[xi,yi,zi,ti]
                    if (fden>1) : fstd = np.sqrt(fstd/(fden-1))
                    
                    # z-score
                    if (mask[xi,yi,zi]>0) and (fstd>0) :
                        for ti in range(skip_first, fmri.shape[T]-skip_last) :
                            fmri[xi,yi,zi,ti] /= fstd
                    else :
                        for ti in range(skip_first, fmri.shape[T]-skip_last) :
                            fmri[xi,yi,zi,ti] = 0
        return fmri
    
    
    def input_json_file(json_file) :
        import json
        
        print("Loading :"+json_file)
        
        with open(json_file, 'r') as f:
            data = json.load(f)
    
        basedir = os.path.dirname(json_file)
    
        subject = []
        run = []
        fmri = []
        mask = []
        transform = []
        for record in data :
            subject.append(int(record['subject']))
            run.append(int(record['run']))
            fmri.append(os.path.join(basedir, str(record['fmri'])))
            mask.append(os.path.join(basedir, str(record['mask'])))
            transform.append(os.path.join(basedir, str(record['transform'])))
     
        print("subjects = "+str(subject))
        print("runs = "+str(run))
        print("fmri = "+str(fmri))
        print("mask = "+str(mask))
        print("transform = "+str(transform))
    
        return {'fmri':fmri, 'mask':mask, 'transform':transform, 'subject':subject, 'run':run}
    
    inter_subject_correlation(fmri_files, mask_files, transform_files, outdir, nsubjects, subjects=None, nruns=1, runs=None, skip_first=3, skip_last=0, meancutoff=0.0001, groupcutoff=0.5)
    
    
##############################################################Data_preperation#################################################################################################################

    
    data_path = glob.glob ('/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/*_func_preproc_isc19x1_corr.nii.gz'.format(q))
    #data_path = glob.glob ('/Volumes/CI EXTERNAL/Analysis file/Saved files/52/*_func_preproc_isc19x1_corr.nii.gz')
    
    datastr = (data_path[0])
    
    data = nib.load(datastr)
    
    
    
    for i in range(19):
        first_par = image.index_img(data, i)
        AffNi = first_par.affine
        data1 = first_par.get_data()
        data1[np.isnan(data1)] = 0.0
        Ni_imgMean = nib.Nifti1Image(data1, AffNi)
        nib.save(Ni_imgMean, '/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/Participant{}.nii'.format(q, i))
    
    
    
    ListLoc = []
    
    for i in range(19):
        d = '/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/Participant{}.nii'.format(q, i)
        ListLoc.append(d)


##############################################################Nipype_pipeline#################################################################################################################



    experiment_dir = '/Users/christiaanbecker/Internship'
    output_dir = 'datasink'
    working_dir = 'workingdir'
    
    from nipype.interfaces.matlab import MatlabCommand
    
    MatlabCommand.set_default_paths('/Applications/MATLAB_R2015b.app/bin/matlab')
    
    
    spm.SPMCommand.set_mlab_paths('/Applications/MATLAB_R2015b.app/bin/matlab')
    
    
    onesamplettestdes = Node(OneSampleTTestDesign(),
                             name="onesampttestdes")
    
    
    onesamplettestdes.inputs.in_files = ListLoc
    #onesamplettestdes.inputs.in_files = [('/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/Participant0.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant1.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant2.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant3.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant4.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant5.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant6.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant7.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant8.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant9.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant10.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant11.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant12.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant13.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant14.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant15.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant16.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant17.nii'),('/Volumes/CI EXTERNAL/Analysis file/Saved files/Participant18.nii')]
    
    level2estimate = Node(EstimateModel(estimation_method={'Classical': 1}),
                          name="level2estimate")
    
    
    level2conestimate = Node(EstimateContrast(group_contrast=True),
                             name="level2conestimate")
    
    cont1 = [('Group', 'T', ['mean'], [1])]
    level2conestimate.inputs.contrasts = cont1
    
    # Threshold - thresholds contrasts
    level2thresh = Node(Threshold(contrast_index=1,
                                  use_topo_fdr=True,
                                  use_fwe_correction=False,
                                  extent_threshold=0,
                                  height_threshold=0.005,
                                  height_threshold_type='p-value',
                                  extent_fdr_p_threshold=0.05),
                        name="level2thresh")
    
    datasink = Node(DataSink(), name="datasink")
    
    
    # Initiation of the 2nd-level analysis workflow
    l2analysis = Workflow(name='spm_l2analysis')
    l2analysis.base_dir = opj(experiment_dir, working_dir)
    
    
    l2analysis.connect(onesamplettestdes, 'spm_mat_file', level2estimate, 'spm_mat_file')
    
    l2analysis.connect(level2estimate, 'spm_mat_file', level2conestimate, 'spm_mat_file')
    l2analysis.connect(level2estimate, 'beta_images', level2conestimate, 'beta_images')
    l2analysis.connect(level2estimate, 'residual_image', level2conestimate, 'residual_image')
    
    #l2analysis.connect(level2conestimate, 'spm_mat_file', level2thresh, 'spm_mat_file')
    #l2analysis.connect(level2conestimate, 'spmT_images', level2thresh, 'stat_image')
    
    l2analysis.connect(level2conestimate, 'spm_mat_file', datasink, '2ndLevel.@spm_mat')
    l2analysis.connect(level2conestimate, 'spmT_images', datasink, '2ndLevel.@T')
    l2analysis.connect(level2conestimate, 'con_images', datasink, '2ndLevel.@con')
    
    #l2analysis.connect(level2thresh, 'thresholded_map', datasink, '2ndLevel.@threshold')
    
    
    l2analysis.run()
    
    
    
    shutil.move("/Users/christiaanbecker/Internship/workingdir", "/Volumes/CI EXTERNAL/Analysis file/Saved files/{}/workingdir".format(q))


